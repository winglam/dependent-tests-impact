\section{Introduction}
\subsection{The Test Independence Assumption}
A principle of unit testing~\cite{} is that each unit test should properly initialize (or mock) the execution environment and/or any resources it will use. Likewise, after test execution, it should reset the execution environment and external resources to avoid affecting other tests' execution. In other words, each unit test should be independent from one another -- executing a unit test suite in any order should not affect any test's result. In practice, however, developers often make the mistake of not adhering to this principle thereby violating the test independence assumption and producing order-dependent tests -- tests whose execution results depend on the execution of other tests.

Test independence~\cite{} implies that no one test should affect another's result and no matter what order tests of a test suite are executed in, the results of the tests should be the same. Tests that do not reproduce the same result when executed in different orders are called dependent tests. Typically these dependent tests are a result of a tests' reliance on some global variable, file system, database, etc. which might be altered by another test. 

Let's consider the example below where Test2 is a dependent test and x is a global variable.

\begin{CodeOut}
\begin{alltt} 
//x is a global varialbe with 1 as the initial value
public void test1() \{
    x = 0;
\}
public void test2() \{
    assert x = 0;
\}
\end{alltt}
\end{CodeOut}

In this example running Test1 then Test2 will have different results than running Test2 then Test1. 

The two major consequences of having dependent tests is that they can often lead to spurious bug reports and can mask faults in a program. The implications of spurious bug reports was made apparent by Eclipse developers when they investigated a bug in SWT~\cite{} for more than a month before realizing that the reason why tests were failing was due to the order in which they were ran as opposed to the changes in their code. Additionally, dependent tests can also mask faults as made apparent by two dependent tests found in the Apache CLI library~\cite{}.


\subsection{Test Prioritization}
The regression testing technique, test prioritization~\cite{}, generates an order for which tests should be ran so that the ones that are likely to fail are executed first. It can also be used to allow testers to meet a code coverage criterion earlier in the test process. Techniques like this is often employed to minimize the time it would take for test suites to reveal bugs. 

In this paper, we focus on three well-known, coverage-based test prioritization techniques.

\begin{enumerate}
\item Random prioritization randomly generates an order for the test cases in a test suite. The will serve as an additional control in our studies to help us better understand the implications of test prioritization techniques compared to just changing the order in which the tests are ran.

\item Statement coverage prioritizes test cases based on the total number of statements executed by a test. Statement coverage can also prioritize tests based on the number of additional statements a test will cover.

\item Function coverage prioritizes test cases based on the total number of functions executed by a test. A test must completely exit a function in order for it be counted. Function coverage can also prioritize tests based on the number of additional functions a test will cover.

\end{enumerate}

Due to how test prioritization can affect the order in which tests from a test suite are ran, a test prioritization technique may theoretically reveal dependent tests. When dependent tests are revealed from these techniques developers may incorrectly assume that the reason why their tests are failing is because of changes to their code.

The example below shows how test dependence can affect the execution results of a test suite when the execution order of the test suite is generated by total statement coverage test prioritization. When \CodeIn{testBar()} is executed before \CodeIn{testFoo()}, both tests should pass. However an order generated by test prioritization would have \CodeIn{testFoo()} execute before \CodeIn{testBar()}, because \CodeIn{testFoo()} executes two lines of code while \CodeIn{testBar()} only executes one line of code. In the case that \CodeIn{testFoo()} executes before \CodeIn{testBar()}, \CodeIn{testBar()} would fail because \CodeIn{x} would be set to 2 by \CodeIn{testFoo()}. 

\begin{CodeOut}
\begin{alltt} 
//x is a global varialbe with 1 as the initial value
public int foo() \{
    x += 1;
    return x;
\}
public int bar() \{
    return x;
\}
public void testBar() \{
    assert bar() == 1;
\}
public void testFoo() \{
    assert foo() == 2;
\}
\end{alltt}
\end{CodeOut}

\subsection{Contributions}
